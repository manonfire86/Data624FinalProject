---
title: "Final Project"
author: "Hector Santana, Harris Dupre, Christopher Ayre"
date: "5/9/2022"
output: html_document
---

Our initial step is to import the relevant libraries containing the requisite models of this analysis.

```{r libraries, message=FALSE, warning=FALSE}

library(mlbench)
library(randomForest)
library(caret)
library(party)
library(Cubist)
library(dplyr)
library(rpart.plot)
library(kernlab)
library(earth)
library(nnet)
library(DataExplorer)
library(RANN)
library(corrplot)
pacman::p_load(tidyverse,janitor,DataExplorer,knitr,arsenal,kableExtra,car,geoR,caret,
               psych,gridExtra,DMwR2,lmtest,pscl,MKmisc,ROCR,survey,stats,rstatix,Rcpp,
               corrplot,forecast,cowplot)

library(mice)
library(RColorBrewer)
library(VIM)
library(openxlsx)

```

To create ease around the data importation process we converted the excel files into CSV and stored them in a GitHub repository.

```{r Importation}


studenttrainingdata = read.csv('https://raw.githubusercontent.com/manonfire86/Data624FinalProject/main/StudentData.csv')

studenttestdata = read.csv('https://raw.githubusercontent.com/manonfire86/Data624FinalProject/main/StudentEvaluation.csv')

```

The below exploratory analysis indicates that missing values are fairly low. For our model to be robust and dynamic we will impute missing data, filter out correlations, near zero variables, scale the data, and center the data in our preprocess methodology.This will remove collinearity, remove skew, normalize distributions, scale the data, and remove non significant variables.


```{r}
str(studenttrainingdata)
```

```{r}
summary(studenttrainingdata)
```

```{r}
dim(studenttrainingdata)
```


```{r dataexploration}
df_features <- studenttrainingdata %>%
  dplyr::select(-c(`Brand.Code`))

correlation = cor(df_features, use = 'pairwise.complete.obs')
corrplot(correlation, 'ellipse', type = 'lower', order = 'hclust',
         col=brewer.pal(n=8, name="RdYlBu"), tl.cex=0.5)

mice_plot <- aggr(studenttrainingdata, col=c('navyblue','yellow'),
                    numbers=TRUE, sortVars=TRUE,
                    labels=names(studenttrainingdata), cex.axis=.7,
                    gap=3, ylab=c("Missing data","Pattern"))

```

```{r}
plot_missing(studenttrainingdata)
plot_histogram(studenttrainingdata)
plot_density(studenttrainingdata)
plot_boxplot(
  data = studenttrainingdata,
  by = "PH")



```




```{r datatransformation}

set.seed(100)

studentrainingdata <- studenttrainingdata[complete.cases(studenttrainingdata$PH),]
preprocess_data_model = preProcess(studenttrainingdata, c("center", "scale", "knnImpute", "corr", "nzv"))
new_dataset = predict(preprocess_data_model,studenttrainingdata)


```

We will now split our data into a training set and validation set to analyze model outputs. Given the evaluation set we will need to verify our model analytics using RMSE, R^2, and MAE prior to running our predictions. Obtaining a model with a combination of the lowest RMSE, highest R^2, and lowest MAE will be optimal.

```{r validation}

training_partition = createDataPartition(new_dataset$PH,p=.8,list=FALSE)

training_df = new_dataset[training_partition,]
validation_df = new_dataset[-training_partition,]


```


We will now build models using various linear, nonlinear, and tree based approaches.

# Linear Models

## Ordinary Least Regression

```{r models, echo = T, results = 'hide'}

olrmod = train(PH~.,data = training_df,method='lm',trControl=trainControl('cv',number=10))

olrpred = predict(olrmod,validation_df)
olrpred_results = postResample(pred = olrpred, obs = validation_df$PH)


```

## Partial Least Squares

```{r model2, echo = T, results = 'hide'}

pls_mod = train(PH~.,data = training_df,method='pls',trControl=trainControl('cv',number=10),center=T,tunelength=20)

plot(pls_mod)

plspred = predict(pls_mod,validation_df)
plspred_results = postResample(pred = plspred, obs = validation_df$PH)


```


# Ridge Regression


```{r model3, echo = T, results = 'hide'}
set.seed(100)

rrfit = train(PH~.,data=training_df,method='ridge',tuneGrid=data.frame(.lambda=seq(0,.1,length=15)),trControl=trainControl('cv',number=10))

plot(rrfit)

rrpred = predict(rrfit,validation_df)
rrpred_results = postResample(pred = rrpred, obs = validation_df$PH)


```






## Non Linear Models

# Neural Networks

```{r model4, echo = T, results = 'hide', warning=FALSE}

set.seed(100)
nnetmod = train(PH~.,data=training_df,
                  method = "avNNet",
                  preProc = c("center", "scale"),
                  tuneGrid = expand.grid( .decay = c(0, 0.01, .1), .size = c(1:10), .bag= F ),
                  trControl = trainControl(method = "cv",number = 10),
                  linout = T,
                  trace= F,
                  MaxNWts = 5 * (ncol(training_df) + 1) + 5 + 1,
                  maxit = 500)

nnetpred = predict(nnetmod,validation_df)
nnetpred_results = postResample(pred = nnetpred, obs = validation_df$PH)


```



# MARS

```{r model5, echo = T, results = 'hide'}

set.seed(100)
marsmod = train(PH~.,data=training_df,method='earth',trControl=trainControl(method='cv'))

marspred = predict(marsmod,validation_df)
marspred_results = postResample(pred = marspred, obs = validation_df$PH)


```



# SVM
```{r model6, echo = T, results = 'hide'}
set.seed(100)
svmmod = train(PH~., data = training_df,
               method= "svmLinear",
               trControl = trainControl(method = "repeatedcv",number = 10, repeats=3),
               tuneLength = 10)

svmpred = predict(svmmod,validation_df)
svmpred_results = postResample(pred = svmpred, obs = validation_df$PH)


```


# KNN


```{r model7, echo = T, results = 'hide'}

set.seed(100)
knnmod = train(PH~., data = training_df,
               method= "knn",
               trControl = trainControl(method = "repeatedcv",number = 10, repeats=3),
               tuneLength = 10)

knnpred = predict(knnmod,validation_df)
knnpred_results = postResample(pred = knnpred, obs = validation_df$PH)

```


## Trees

# Random Forest

```{r model8, echo = T, results = 'hide'}


randomforest_model = train(PH~.,data=training_df,method='rf',
                       preProcess = c('center', 'scale'),trControl=trainControl('cv'))

randomforest_pred = predict(randomforest_model, validation_df)
randomforest_results = postResample(pred = randomforest_pred, obs = validation_df$PH)


```

# Boosted Trees

```{r model9, echo = T, results = 'hide'}


gbm_model = train(PH~.,data=training_df,method='gbm',tuneGrid=expand.grid(.interaction.depth = seq(1, 7, by = 2),
                        .n.trees = seq(100, 1000, by = 100),
                        .shrinkage = c(0.01, 0.1),
                        .n.minobsinnode = 8),
                       trControl=trainControl('cv'))

gbm_pred = predict(gbm_model, validation_df)
gbm_results = postResample(pred = gbm_pred, obs = validation_df$PH)



```

# Cubist

```{r model10, echo = T, results = 'hide'}


cub_model = train(PH~.,data=training_df,method='cubist',
                       preProcess = c('center', 'scale'),trControl=trainControl('cv'))

cub_pred = predict(cub_model, validation_df)
cub_results = postResample(pred = cub_pred, obs = validation_df$PH)



```

# Single Tree


```{r model11, echo = T, results = 'hide'}


rp_model = train(PH~.,data=training_df,method='rpart2',
                       preProcess = c('center', 'scale'),trControl=trainControl('cv'))

rp_pred = predict(rp_model, validation_df)
rp_results = postResample(pred = rp_pred, obs = validation_df$PH)

plot(rp_model)


```

# GLMNET


```{r model12, echo = T, results = 'hide'}


glm_model = train(PH~.,data=training_df,method='glmnet',
                       preProcess = c('center', 'scale'),trControl=trainControl('cv'))

glm_pred = predict(glm_model, validation_df)
glm_results = postResample(pred = glm_pred, obs = validation_df$PH)


plot(glm_model)

```


# PCR

```{r model13, echo = T, results = 'hide'}


pcr_model = train(PH~.,data=training_df,method='pcr',
                       preProcess = c('center', 'scale'),trControl=trainControl('cv'))

pcr_pred = predict(pcr_model, validation_df)
pcr_results = postResample(pred = pcr_pred, obs = validation_df$PH)


plot(pcr_model)

```

## Evaluation

Aggregating the model results we see our cubist model performs the best among the 13 selected model types. The multi node linear model tree based methodology accounts best for the various intricacies of the data set. There is of course the risk of over fitting, however the cubist model we discerned to be best fit in this scenario.

```{r}
titles <- list("OLR","PLS","RR","NNet","MARS","SVM","KNN","Random Forest","Boosted Model","Cubist","RPart","GLMNET","PCR")
results <- list(olrpred_results,plspred_results,rrpred_results,nnetpred_results,marspred_results,svmpred_results,knnpred_results,randomforest_results,gbm_results,cub_results,rp_results,glm_results,pcr_results)

df = NULL
for (x in 1:length(results)) {
  Model = titles[[x]]
  RMSE = unname(results[[x]]["RMSE"])
  Rsquared = unname(results[[x]]["Rsquared"])
  MAE = unname(results[[x]]["MAE"])
    
  df = rbind(df,data.frame(Model,RMSE,Rsquared,MAE))
}

knitr::kable(df[order(df$Rsquared,decreasing=TRUE),], digits=4, row.names=F)
```


```{r evaluation}

ggplot(data=df,aes(x=Model,y=RMSE)) +geom_bar(stat='identity',aes(fill=Model))+ coord_flip()

ggplot(data=df,aes(x=Model,y=Rsquared)) +geom_bar(stat='identity',aes(fill=Model))+ coord_flip()

ggplot(data=df,aes(x=Model,y=MAE)) +geom_bar(stat='identity',aes(fill=Model))+ coord_flip()



```

# Variable Importance

Using the cubist model we can discern how variables are weighted for predictor 'PH'. Mnf.Flow is the most significant variable in the model. 

```{r varimp}

cub_var_imp = varImp(cub_model)

ggplot(data=cub_var_imp$importance,aes(x=reorder(rownames(cub_var_imp$importance), Overall),y=Overall)) +geom_bar(stat='identity',aes(fill=rownames(cub_var_imp$importance)))+ coord_flip() +theme(legend.position = "none") + labs(x='Variables')



```


# Predictions

```{r forecast}
#studenteval_scaled = preProcess(studenttestdata, c("center", "scale","corr", "nzv"))
#studenteval_scaled_dataset = predict(studenteval_scaled,studenttestdata)
eval_cub_pred = predict(cub_model, studenttestdata)
scaled_ph = scale(studenttrainingdata$PH, center= TRUE, scale=TRUE)
scaledeval_predictions = eval_cub_pred * attr(scaled_ph, 'scaled:scale') +   attr(scaled_ph, 'scaled:center')
eval_df = data.frame(scaledeval_predictions)
#write.xlsx(eval_df, 'FinalProject_Predictions.xlsx')
eval_df


```
